{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbb831d-40f4-4e1e-ad3b-6d458a60981e",
   "metadata": {},
   "source": [
    "# Wordwright Tutorial\n",
    "\n",
    "## Motivation\n",
    "In today's world, text is omnipresent, which is more than just a form of communication. From the briefest tweets to in-depth blog posts, from academic papers to business emails, this digital landscape is full of textual content. In such a text-saturated environment, the ability to read, analyze and derive meaning from written content is essential and meaningful. This is where our comprehensive text analysis package `wordwright` enters the picture. It's not only a text-processing tool, it's a bridge to understanding the world from overwhelming text. Our package empowers various professionals by meeting their demands through cleaning irrelevant punctuations, calculating the number of identified keywords and sentences, detecting the paragraph language, and ranking the word frequency. Potential users such as marketers, journalists, educators and healthcare professionals could benefit from this package.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b8070-4864-488d-8e90-a70b1dce7076",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this vignette, we demonstrate how `wordwright` can be used to analyze customer reviews that are similar to those typically seen on rental platforms like Airbnb. After each visit, users will take the time to submit a review to assist hosts in improving their accommodations and service as a valuable part of the community ecosystem. These reviews can highlight the unique features of a stay that may not be apparent from the description, such as the comfort of the bedding or even local tips that made your stay special. Whether you are a data scientist, a student, or just someone curious about text analytics, `wordwright` provides intuitive functions to transform raw text into actionable data.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21f029a-380b-40c3-b8f2-6bc056d7a990",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langdetect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordwright\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_text\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordwright\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_text\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordwright\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m language_detection\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordwright\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcount_sentences\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count_sentences\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordwright\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mword_frequency\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frequent_words\n",
      "File \u001b[0;32m~/UBC_MDS/b4/524/wordwright/src/wordwright/language_detection.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangdetect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect, LangDetectException\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlanguage_detection\u001b[39m(text):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    Detect if the text is in English or not.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    'Not English'\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langdetect'"
     ]
    }
   ],
   "source": [
    "from wordwright.preprocessing import load_text\n",
    "from wordwright.preprocessing import clean_text\n",
    "from wordwright.language_detection import language_detection\n",
    "from wordwright.count_sentences import count_sentences\n",
    "from wordwright.word_frequency import frequent_words\n",
    "from wordwright.count_keywords import count_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc9a6b-0240-4a81-9d19-1fec7476caa9",
   "metadata": {},
   "source": [
    "## Getting Started with Text Files\n",
    "Before our analysis, we need to compose several customer reviews and save them as text files for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d96b56-636d-42b9-b23a-5693e7b1b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long positive review of a city apartment\n",
    "review1 = \"\"\"Our stay at Skyline Plaza was truly exceptional. The apartment offered \n",
    "breathtaking views of the city skyline, making every morning a luxurious experience. \n",
    "Inside, modern amenities like a fully-equipped kitchen, high-speed internet, \n",
    "and a smart TV provided exceptional comfort. The spacious bedrooms, each with \n",
    "ultra-comfortable beds, ensured restful nights after exploring the city's \n",
    "breathtaking sights. Located at the heart of the city, the apartment's proximity \n",
    "to public transport, diverse restaurants, and shops was incredibly convenient. \n",
    "Our host was wonderfully accommodating, providing a detailed city guide and \n",
    "personal recommendations for dining with views of the skyline. For anyone seeking \n",
    "a mix of modern luxury and convenient city living, this apartment is a \n",
    "perfect choice. Its luxurious amenities and prime location make it a \n",
    "standout choice for an exceptional city experience.\n",
    "\"\"\"\n",
    "\n",
    "# Short positive review of a cozy cottage\n",
    "review2 = \"\"\"Cozy Cottage was a quiet, charming escape from the busy city life. \n",
    "The garden was delightful, and the location was quiet yet convenient. \n",
    "A perfect weekend getaway! Highly recommend!\n",
    "\"\"\"\n",
    "\n",
    "# A medium length negative review \n",
    "review3 = \"\"\"Although the location nestled right in the heart of the city, \n",
    "our stay was marred by disappointment. The first sign of trouble was the linens; \n",
    "they had a strange, unpleasant smell, as if they hadn't been washed. \n",
    "The bathroom, too, has a strange odor that made it feel unclean and unpleasant. \n",
    "Overall, the lack of cleanliness cast a shadow over our visit, \n",
    "turning our stay into an unpleasant experience. The location, unfortunately, \n",
    "couldn't make up for these  disappointing aspects.\n",
    "\"\"\"\n",
    "\n",
    "# Writing the reviews to text files\n",
    "filenames = [\"long_pos_review.txt\", \n",
    "             \"short_pos_review.txt\", \n",
    "             \"medium_neg_review.txt\"]\n",
    "reviews = [review1, review2, review3]\n",
    "\n",
    "for filename, review in zip(filenames, reviews):\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2faad-f1b5-4139-befb-d9b513dee477",
   "metadata": {},
   "source": [
    "Now that we have our text files, let's dive into each function and see how it contributes to our text analysis workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434195f-885a-4f62-b45f-6f42cc2075ad",
   "metadata": {},
   "source": [
    "## Function 1: Loading Text Data\n",
    "The `load_text` function reads the content of a text file without altering it. For our Airbnb reviews, we have three different text files containing reviews of varying lengths and details. We'll load each one and prepare them for cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae12f0-ebf5-4e8e-b4ee-fe102011b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_long_pos_review = load_text(\"long_pos_review.txt\")\n",
    "print(raw_long_pos_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea63b8a-35b5-47c4-ac61-0582efa1c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_short_pos_review = load_text(\"short_pos_review.txt\")\n",
    "print(raw_short_pos_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f8fde-af62-4567-a75b-9d3863d81d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_medium_neg_review = load_text(\"medium_neg_review.txt\")\n",
    "print(raw_medium_neg_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f72327-b1d9-4309-a411-75af336ee3a5",
   "metadata": {},
   "source": [
    "## Function 2: Cleaning the Text\n",
    "The `clean_text` function removes all punctuations and whitespaces and makes all words lowercase, which ensures text uniform and easier to analyze, especially for word counting and searching (as shown in later sections). Using this function, we ensure our analysis is not skewed by formatting inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7f0bc-f34a-48f1-8107-5b54e0dcef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_short_pos_review = clean_text(raw_short_pos_review)\n",
    "print(cleaned_short_pos_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce017743-93b4-4498-a244-605de4d2e6a0",
   "metadata": {},
   "source": [
    "Now let's clean the other two pieces of reviews. Note that in the reviews shown below, we also take care to preserve the nuances of the English language. For example, apostrophes that are part of contractions or possessive forms—like in \"hadn't\" or \"city's\"—are maintained. By doing so, our analysis respects the linguistic integrity and retains the text's original meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a1d53-a123-422c-a2c6-ceaa055ac9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_long_pos_review = clean_text(raw_long_pos_review)\n",
    "print(cleaned_long_pos_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60dccfa-b5e5-4cb3-b88b-0d8883f92319",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_medium_neg_review = clean_text(raw_medium_neg_review)\n",
    "print(cleaned_medium_neg_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c695034-ce42-4323-9be8-4d39c7bef929",
   "metadata": {},
   "source": [
    "## Function 3: Detecting Language\n",
    "\n",
    "The `language_detection` function is designed to identify whether a given text is written in English. Language detection is crucial for platforms like Airbnb that operate globally and handle reviews in many languages. Analytical tools are often language-specific, and running an English language analysis tool on non-English text would yield invalid results. For text analysis purposes, it is important to separate reviews by language, ensuring customer reviews are accessible and useful for the platform's analytical purposes.\n",
    "\n",
    "This function accepts a string as input and determines language. The function returns \"English\" if it detects that the text is in English, \"Not English\" for any other language, and \"Language detection error\" if it encounters an error during the detection process. When English is detected, we will be ready for the following text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9e062-ea6a-4ae9-b0eb-f3877aa4a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_detection(raw_short_pos_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373394a9-5292-4d8a-a79c-e18e59bec502",
   "metadata": {},
   "source": [
    "Detect a text not in English, take Spanish as an example, the function will return \"Not English\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71786a97-e820-4bda-82c1-a1228d492860",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_in_spanish = \"\"\"\n",
    "La estancia fue encantadora, con un servicio impecable, \n",
    "un ambiente acogedor y una ubicación privilegiada que \n",
    "superó todas las expectativas. ¡Una experiencia \n",
    "verdaderamente memorable!\n",
    "\"\"\"\n",
    "language_detection(review_in_spanish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f18a2a-1ee7-449f-845a-1c21baa881e5",
   "metadata": {},
   "source": [
    "## Function 4: Counting Sentences\n",
    "\n",
    "The `count_sentence` function counts the number of sentences in a given text. It is useful to understand the text structure in readability assessments, summarization tasks, or content analysis to prepare for a more in-depth text analysis. It can accurately identify sentence boundaries, which can vary with periods, exclamation marks, question marks, or other punctuation used to denote the end of a sentence. User could identify specific punctuations which use to seperate each sentence and thus calculate the total number of sentences. \n",
    "\n",
    "Counting sentences about customer reviews can provide a quick and quantifiable measure of user satisfaction, facilitate data-driven insights and enhance the analysis and presentation of textual review data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8c5f1-b6d2-4d0f-a840-3099243bbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate each sentence using period and exclamation mark\n",
    "customer_1 = count_sentences(raw_long_pos_review, [\".\", \"!\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af5868-739a-45ad-b8f8-47e0153db359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate each sentence using period and exclamation mark\n",
    "customer_2 = count_sentences(raw_short_pos_review, [\".\", \"!\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1da300-6c13-4864-9c7e-e3f82698fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate each sentence using period\n",
    "customer_3 = count_sentences(raw_medium_neg_review, [\".\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17da206-e133-46d6-9d4b-ba0bf4370d08",
   "metadata": {},
   "source": [
    "## Function 5: Analyzing Word Frequency\n",
    "\n",
    "### Integrated Text Cleaning\n",
    "The `frequent_words` function has incorporated text cleaning within its process. This means that users don't need to separately clean their text with the `clean_text` function before analysis; `frequent_words` will handle both cleaning and word frequency analysis in one step. Specifically, the `frequent_words` count the occurrences of each unique word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea3867-0b34-48d7-9bca-e9ad0a687c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_words(raw_short_pos_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f1a3c-76eb-4fbb-8fb4-03cee58e027d",
   "metadata": {},
   "source": [
    "### Stopwords Filtering\n",
    "In text analysis, the frequency of words can reveal a lot about the content. However, not all words carry the same weight in conveying meaning. This is where the `frequent_words` function of the wordwright package becomes particularly valuable.\n",
    "\n",
    "**User-defined Stopwords List**  \n",
    "Stopwords are commonly used words in any language, like \"the,\" \"is,\" and \"in,\" which may not add significant meaning. The `frequent_words` function, allowing for removing user-defined stopwords, can focus on the more meaningful words that could provide insights into the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63beee5d-5076-41ae-a8fa-7de902c06f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stopwords = [\"the\", \"a\", \"is\", \"was\", \"and\", \"yet\", \"but\", \n",
    "                  \"from\", \"to\", \"in\" \"at\", \"on\"]\n",
    "frequent_words(raw_short_pos_review, stopwords=user_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192a647-f45f-4778-9ac2-51dba6095a83",
   "metadata": {},
   "source": [
    "**Leveraging NLTK's Comprehensive Stopwords List**  \n",
    "For a more thorough cleaning of our text data, we can utilize the Natural Language Toolkit (NLTK), a leading package to work with human language data (see details [here](https://www.nltk.org/)). NLTK provides an extensive list of stopwords commonly used in the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c2064-ad63-400c-a3b0-63fd5796b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2fa50d-c7a4-4c03-a13e-ea43fc91329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_words(raw_short_pos_review, stopwords=nltk_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de4010-9830-4ed5-a612-63dc84060273",
   "metadata": {},
   "source": [
    "**Extending and Customizing Stopwords List**   \n",
    "In scenarios where the default NLTK stopwords may not be sufficient for analysis in depth, users can extend the NLTK stopwords list with their own set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce127457-1159-4e04-8e65-32965acbf8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the default NLTK stopwords\n",
    "custom_stopwords = set(nltk_stopwords)\n",
    "\n",
    "# Define additional stopwords that are irrelevant to the analysis\n",
    "additional_stopwords = {'weekend', 'location', 'weekend', 'life', 'city'}\n",
    "\n",
    "# Combine the default stopwords with the additional ones\n",
    "custom_stopwords.update(additional_stopwords)\n",
    "\n",
    "# Ensure that the custom stopwords list is unique\n",
    "custom_stopwords = list(set(custom_stopwords))\n",
    "\n",
    "# Display the most common words excluding the customized stopwords\n",
    "frequent_words(raw_short_pos_review, stopwords=custom_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80e6ee-d328-47fd-91a8-a3f38356b4e8",
   "metadata": {},
   "source": [
    "### Displaying the Most Frequent Words\n",
    "The output of the `frequent_words` function is a `Counter` object (see details of `Counter` [here](https://docs.python.org/3/library/collections.html#collections.Counter)), a specialized dictionary from Python's collections module designed for counting hashable objects.\n",
    "One useful method available on a Counter object is `most_common()`(see details of the function [here](https://docs.python.org/3/library/collections.html#collections.Counter.most_common)). This method allows quickly identifying the most frequently occurring items and their counts as a `list`. You can also specify a number to return the top N most frequent words.\n",
    "\n",
    "This method is particularly handy when dealing with large texts and you want to focus on the most relevant words, such as identifying key themes in customer reviews or the most mentioned terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b20bd-ec9c-47f7-8041-ba43fd1b22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_long_pos_review = frequent_words(raw_long_pos_review, \n",
    "                                        stopwords=nltk_stopwords\n",
    "                                       ).most_common(10)\n",
    "top_10_long_pos_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac49c7-48b6-4a10-abd7-cdfda2bb4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_short_pos_review = frequent_words(raw_short_pos_review, \n",
    "                                        stopwords=nltk_stopwords\n",
    "                                       ).most_common(3)\n",
    "top_3_short_pos_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f313d-ca7d-4d31-adc7-4cf983b8c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_medium_neg_review = frequent_words(raw_medium_neg_review, \n",
    "                                         stopwords=nltk_stopwords\n",
    "                                        ).most_common(5)\n",
    "top_5_medium_neg_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a955824-fb5c-4284-a4dd-3c6362f945e1",
   "metadata": {},
   "source": [
    "## Function 6 Counting Keywords\n",
    "\n",
    "This is a function that counts keywords in a text. The user gets to specify the keywords to look for and the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cfc5b-d8ed-4523-bfc3-42310946c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_keywords(raw_long_pos_review, ['breathtaking', 'exceptional', 'city\\'s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741e69d-f343-4d89-a967-c665742b1d9c",
   "metadata": {},
   "source": [
    "The function counts these words correctly. Moreover, notice that it forces lower case and ignores punctuation, with the exception of the apostrophes used for sentence contraption. This is because our function first preprocesses the text and the keywords by forcing lower case and removing all punctuation except for the apostrophes when evaluating word counts. This includes cases where a hyphen is used to join two words (ex: fully-equipped is treated as fullyequipped). These rules extend to both the text and the keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca25b70-3e77-40cf-9a26-c4971297b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_keywords(raw_long_pos_review, ['fullyequipped'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea08415-59a3-45c8-9db6-30012d095c57",
   "metadata": {},
   "source": [
    "Here we see that the word \"fullyequipped\" has a count of 1, even though in the text there is no literal word \"fullyequipped\". This is the result of the preprocessing taken before evaluating word counts, which leads to the removal of the character \"-\" connecting the words \"fully\" and \"equipped\".\n",
    "\n",
    "Sometimes an user may put in the same word in the keyword list multiple times on accident or by intention. In the output, the count for that word only appears once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cc4af-1b09-4906-95ac-8acde9c05740",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_keywords(raw_short_pos_review, ['cozy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8318bea-1ae6-493e-801c-321d2d5601a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_keywords(raw_short_pos_review, ['cozy', 'cozy', 'Cozy', 'cozy!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4dc353-23f2-4a2d-afdb-f40ca5554620",
   "metadata": {},
   "source": [
    "Notice that punctuation and case do not make a new word. The preprocessing applied to the keywords would map all of them onto the vanilla version of the word."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
